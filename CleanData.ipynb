{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there g...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives around here though</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     v1  \\\n",
       "0   ham   \n",
       "1   ham   \n",
       "2  spam   \n",
       "3   ham   \n",
       "4   ham   \n",
       "\n",
       "                                                                                                    v2  \\\n",
       "0  Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there g...   \n",
       "1                                                                        Ok lar... Joking wif u oni...   \n",
       "2  Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive ...   \n",
       "3                                                    U dun say so early hor... U c already then say...   \n",
       "4                                        Nah I don't think he goes to usf, he lives around here though   \n",
       "\n",
       "  Unnamed: 2 Unnamed: 3 Unnamed: 4  \n",
       "0        NaN        NaN        NaN  \n",
       "1        NaN        NaN        NaN  \n",
       "2        NaN        NaN        NaN  \n",
       "3        NaN        NaN        NaN  \n",
       "4        NaN        NaN        NaN  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "import string\n",
    "\n",
    "pd.set_option('display.max_colwidth', 100)\n",
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "\n",
    "messages = pd.read_csv('spam.csv', encoding = 'latin-1')\n",
    "messages.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5572, 5)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the shape of the 'spam.csv' dataset\n",
    "messages.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "v1               0\n",
       "v2               0\n",
       "Unnamed: 2    5522\n",
       "Unnamed: 3    5560\n",
       "Unnamed: 4    5566\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculating how many blank values each column has\n",
    "messages.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping the columns 'Unnamed: 2', 'Unnamed: 3', 'Unnamed: 4' as over 99% of the elemens are blank\n",
    "messages = messages.drop(labels = ['Unnamed: 2','Unnamed: 3', 'Unnamed: 4'], axis = 1)\n",
    "\n",
    "# Renaming the two remaining columns' headers 'v1' and 'v2' to 'label' and 'text'\n",
    "messages.columns = ['label', 'text']\n",
    "\n",
    "# Converting the labels from string 'spam'/'ham' to binary\n",
    "messages['label'] = np.where(messages['label'] == 'spam', 1, 0)\n",
    "\n",
    "# A function to clean data: converting all the characters to lower case, removing punctuations (such as '!', '^', ..),\n",
    "# tokenizing each message and finally removing stopwords not adding much meaning to a sentence such as 'I', 'it', ..\n",
    "def clean_text(text):\n",
    "    text = \"\".join([char.lower() for char in text if char not in string.punctuation])\n",
    "    tokens = re.split('\\W+', text)\n",
    "    text = [word for word in tokens if word not in stopwords]\n",
    "    return text\n",
    "    \n",
    "# cleanning data using clean_text function\n",
    "messages['cleanned_text'] = messages['text'].apply(lambda x: clean_text(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting data into train and test sets, 80% and 20%, respectively\n",
    "x_train, x_test, y_train, y_test = train_test_split(messages['cleanned_text'], messages['label'], test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1198    [al, moan, n, e, thin, goes, wrong, faultal, de, arguments, r, faultfed, himso, bother, hav, 2go...\n",
       "1617                                                                              [u, download, fring, app]\n",
       "501                                                                                               [ì, come]\n",
       "618                                                  [come, n, pick, ì, come, immediately, aft, ur, lesson]\n",
       "258     [tried, contact, reply, offer, video, handset, 750, anytime, networks, mins, unlimited, text, ca...\n",
       "                                                       ...                                                 \n",
       "4845                                                      [pls, help, tell, ashley, cant, find, number, oh]\n",
       "5152    [idk, im, sitting, stop, shop, parking, lot, right, bawling, eyes, feel, like, im, failure, ever...\n",
       "890                                                                                         [ask, princess]\n",
       "1226    [reply, name, address, receive, post, weeks, completely, free, accommodation, various, global, l...\n",
       "2059                                                          [didnt, see, shadow, get, early, spring, yay]\n",
       "Name: cleanned_text, Length: 1115, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verifying to see how x_test as an example looks like\n",
    "x_test[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving each of x_train, x_test, y_train, y_test as separate csv files in order to use in different models\n",
    "# Ignoring the index and specifying there are headers in the files so the model does not consider the indices and headers as part of the datasets\n",
    "x_train.to_csv('x_train.csv', index = False, header = True)\n",
    "x_test.to_csv('x_test.csv', index = False, header = True)\n",
    "y_train.to_csv('y_train.csv', index = False, header = True)\n",
    "y_test.to_csv('y_test.csv', index = False, header = True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
